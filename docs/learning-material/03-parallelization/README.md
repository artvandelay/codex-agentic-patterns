# Pattern 3: Parallelization

> **"Executing independent operations concurrently for better performance"**

## ğŸ“– Pattern Overview

Parallelization enables agents to execute multiple independent operations simultaneously rather than sequentially. This significantly improves performance for tasks that don't have dependencies.

## ğŸ¯ Key Concepts

1. **Concurrent Execution**: Run independent tasks simultaneously
2. **Dependency Management**: Identify which tasks can run in parallel
3. **Result Aggregation**: Collect and combine parallel results
4. **Error Isolation**: Handle failures in parallel tasks independently

## ğŸ” How Codex Implements This

### Location in Codebase
- **Primary**: `codex-rs/core/src/tools/parallel.rs` (lines 47-67)
- **Support**: `codex-rs/core/src/codex.rs` (parallel tool calls)

### Implementation Details

Codex's `ToolCallRuntime` intelligently decides whether to execute tools in parallel or serially:

```rust
// From codex-rs/core/src/tools/parallel.rs
pub(crate) async fn handle_tool_call(
    &mut self,
    call: ToolCall,
    output_index: usize,
    output: &mut [ProcessedResponseItem],
) -> Result<(), CodexErr> {
    let supports_parallel = self.router.tool_supports_parallel(&call.tool_name);
    
    if supports_parallel {
        // Launch task in background
        self.spawn_parallel(call, output_index);
    } else {
        // Wait for pending parallel tasks to complete first
        self.resolve_pending(output).await?;
        
        // Execute serially
        let response = self.dispatch_serial(call).await?;
        output[output_index].response = Some(response);
    }
    
    Ok(())
}
```

### Key Features

1. **Per-Tool Configuration**: Each tool declares if it supports parallelization
2. **Async/Await**: Uses Tokio for efficient concurrent execution
3. **Automatic Ordering**: Serial tools wait for parallel tasks to complete
4. **Error Propagation**: Parallel task failures propagate correctly

## ğŸ’¡ Real-World Example from Codex

When the LLM wants to read 3 files:

```rust
// Sequential (slow):
read("file1.py")  // 10ms
read("file2.py")  // 10ms  
read("file3.py")  // 10ms
// Total: 30ms

// Parallel (fast):
spawn(read("file1.py"))  // }
spawn(read("file2.py"))  // } All run concurrently
spawn(read("file3.py"))  // }
await_all()
// Total: ~10ms
```

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LLM Returns 3 Tool Calls             â”‚
â”‚   1. read_file("a.py")                       â”‚
â”‚   2. read_file("b.py")                       â”‚
â”‚   3. shell("ls")  â† Must run serially        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Tool Router        â”‚
         â”‚  Check each tool     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                 â”‚
    â–¼                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tools 1 & 2 â”‚               â”‚   Tool 3     â”‚
â”‚ (parallel)  â”‚               â”‚  (serial)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                             â”‚
  Spawn async                    Must wait
       â”‚                             â”‚
       â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”   â”‚   â”‚             â”‚
â”‚  â”‚Task 1â”‚    â”‚Task 2â”‚   â”‚   â”‚   Task 3    â”‚
â”‚  â”‚ a.py â”‚    â”‚ b.py â”‚   â”‚   â”‚    "ls"     â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”˜   â”‚   â”‚             â”‚
â”‚      â”‚           â”‚       â”‚   â”‚             â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜       â”‚   â”‚             â”‚
â”‚              â”‚           â”‚   â”‚             â”‚
â”‚       Wait for both      â”‚   â”‚  Execute    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚                      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Collect Results â”‚
                 â”‚  Feed to LLM     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ Python Examples

See the example files:
- **`pattern_simple.py`**: Basic parallel execution with asyncio
- **`pattern_advanced.py`**: Tool-aware parallelization
- **`benchmarks.py`**: Performance comparison

## ğŸ”‘ Key Takeaways

1. âœ… **Performance**: 3x-10x speedup for I/O-bound operations
2. âœ… **Scalability**: Handles many concurrent operations efficiently
3. âœ… **Smart Execution**: Only parallelizes when safe
4. âœ… **Error Handling**: Isolated failures don't block other tasks
5. âš ï¸ **Complexity**: More complex than sequential execution

## ğŸš€ When to Use

- âœ… Multiple independent file reads
- âœ… Batch API calls to external services
- âœ… Parallel data processing tasks
- âœ… Multiple search queries
- âŒ Tasks with dependencies (must be sequential)
- âŒ Shared mutable state (needs synchronization)

## âš ï¸ Common Pitfalls

### 1. Race Conditions
```python
âŒ BAD: Parallel writes to same file
âœ… GOOD: Parallel reads, or parallel writes to different files
```

### 2. Resource Exhaustion
```python
âŒ BAD: Spawn 1000 tasks simultaneously
âœ… GOOD: Use semaphore to limit concurrency
```

### 3. Deadlocks
```python
âŒ BAD: Task A waits for B, B waits for A
âœ… GOOD: Clear dependency ordering
```

## ğŸ“š Further Reading

- **Codex Source**: `codex-rs/core/src/tools/parallel.rs`
- **Async Rust**: https://rust-lang.github.io/async-book/
- **Tokio Guide**: https://tokio.rs/tokio/tutorial
- **Python asyncio**: https://docs.python.org/3/library/asyncio.html

## ğŸ”— Related Patterns

- **Pattern 1: Prompt Chaining** - Parallel can be one step in chain
- **Pattern 2: Routing** - Router decides what runs parallel
- **Pattern 5: Tool Use** - Tools declare parallel capability

---

**Next**: [Pattern 8: Memory Management â†’](../08-memory-management/README.mdREADME.md)

